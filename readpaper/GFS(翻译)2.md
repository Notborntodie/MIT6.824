[TOC]

### 2.7.2 Implications for Applications

- GFS应用程序可以通过一些简单的技术来适应宽松的一致性模型，包括使用追加而不是覆盖、定期进行检查点、编写自验证、自识别的记录等。
- 实际上，几乎所有的GFS应用程序都通过追加来修改文件，而不是覆盖。这种方法比随机写入更有效，也更具抗应用程序故障的能力。
- 对于多个写入者同时追加到一个文件的情况，记录追加操作的“至少一次追加”语义保留了每个写入者的输出。读取器可以处理时不时出现的填充和重复记录。
- 写入者可以定期进行检查点，以便在应用程序故障后能够恢复。读取器仅处理到最后一个检查点的文件区域，这是已知处于定义状态的。
- 每个记录都包含了一些额外的信息（如校验和），以便验证其有效性。读取器可以使用这些信息来识别并丢弃额外的填充和记录片段。如果需要删除重复记录，读取器可以使用记录中的唯一标识符进行过滤，这些标识符通常也用于命名对应的应用程序实体（如Web文档）。
- 这些记录I/O的功能（除了重复记录的删除）已经包含在GFS的应用程序库中，并适用于Google的其他文件接口实现。

## 3 系统交互 

我们设计系统以最小化主服务器在所有操作中的参与。在此背景下，我们现在描述客户端、主服务器和块服务器如何相互作用以实现数据变异、原子记录追加和快照。

### 3.1 租约和变异顺序

变异是指改变块内容或元数据的操作，例如写入或追加操作。每个变异在所有块副本上执行。我们使用**租约**来维护跨副本的一致变异顺序。

主服务器授予一个块租约给其中一个副本，我们称之为主副本。主副本为所有变异选择一个序列顺序。所有副本在应用变异时都会遵循此顺序。因此，**全局变异顺序**首先由主服务器选择的租约授予顺序定义，并在租约内由主副本分配的序列号定义。

租约机制旨在**最小化**主服务器的管理开销。租约的初始超时为60秒。但只要块正在变异，主副本可以无限期地请求并通常获得主服务器的扩展。这些扩展请求和授予会被塞到主服务器和所有块服务器之间定期交换的心跳消息中。主服务器有时会尝试在租约到期之前撤销租约（例如当主服务器想要禁用正在重命名的文件上的变异时）。即使主服务器失去与主副本的通信，也可以在旧租约到期后安全地向另一个副本授予新租约。

在图2中，我们通过跟踪写入操作的控制流程来说明这个过程。

<img src="http://cdn.zhengyanchen.cn/img202303131536320.png" alt="截屏2023-03-13 15.36.16" style="zoom:70%;" />

1. 客户端向主节点请求当前持有chunk租约以及其他副本的位置。如果没有副本持有租约，主节点将租约授予其选择的一个副本（未显示）。
2. 主节点回复主副本的标识和其他（次要）副本的位置。客户端缓存此数据以供未来的变异使用。只有当主副本无法到达或回复不再持有租约时，客户端才需要再次联系主节点。
3. 客户端将数据推送到所有副本。客户端可以以任意顺序进行此操作。每个chunkserver将在内部LRU缓冲区缓存中存储数据，直到数据被使用或过期为止。通过将数据流与控制流分离，我们可以根据网络拓扑安排昂贵的数据流，而不管哪个chunkserver是主副本。第3.2节进一步讨论了这一点。
4. 一旦所有副本确认已收到数据，客户端向主副本发送写请求。请求标识了先前推送到所有副本的数据。==主副本为接收到的所有变异分配连续的序列号==，可能来自多个客户端，这提供了必要的串行化。它按照序列号顺序将变异应用于其自己的本地状态。

####  这里为什么所以副本已经确认收到数据，客户端才向主副本发送写请求

这是因为主副本在收到写请求后，会为这个请求分配一个序列号，然后将这个请求和它的序列号发送给所有的副本。因此，在客户端向主副本发送写请求之前，必须先将数据推送到所有的副本，并等待它们都确认收到数据，这样才能确保副本之间的数据一致性。否则，如果有任何一个副本没有收到数据，那么这个副本上的数据就会与其他副本不一致，可能会导致数据的损失或不一致。

#### 什么叫序列号顺序将变异应用于其自己的本地状态

"序列号顺序将变异应用于其自己的本地状态"意思是主副本将写操作按照序列号顺序逐一应用到本地的数据状态中。在分布式系统中，多个客户端同时进行写操作可能会导致数据不一致的问题，因此需要对写操作进行序列化处理。通过为每个写操作分配唯一的序列号，可以确保主副本在进行写操作时，按照相同的顺序应用所有的写操作，从而保证所有的副本在完成写操作后都具有相同的数据状态。

#### 所以是客户端发送它想append的记录到所有副本，再由主副本序列化这些记录？

是的，客户端首先将想要追加的记录发送给所有的副本。然后，主副本会按照一定的顺序为接收到的所有追加请求分配连续的序列号，并将这些请求按照序列号顺序应用到它自己的本地状态中。副本会按照主副本分配的序列号顺序应用这些请求。这种方式可以确保所有的副本都按照相同的顺序应用相同的请求，从而保证了数据的一致性。

5. 主副本将写请求转发给所有次要副本。每个次要副本按照主副本分配的相同序列号顺序应用变异。
6. 所有次要副本都向主副本回复，指示它们已完成操作。

5. 主副本回复客户端。在任何副本遇到错误的情况下，错误将报告给客户端。如果在主副本失败，它将不会被分配序列号和转发。客户端请求被视为失败，并且修改的区域处于不一致状态。我们的客户端代码通过重试失败的变异来处理此类错误。在步骤（3）到（7）中进行几次尝试，然后回退到写入的开始重试。

#### 那么如何确认所有副本已收到数据？

在步骤3中，客户端会将数据推送到所有副本，而每个副本都会在接收到数据后向主副本发送确认消息。只有当所有副本都向主副本发送了确认消息后，客户端才会向主副本发送写请求。在步骤6中，主副本会收到来自所有副本的确认消息，才会回复客户端。如果有任何错误发生，主副本也会向客户端发送错误信息。

这段文本介绍了当应用程序进行写操作时，如果写入的数据比较大或跨越多个chunk，GFS客户端代码会将其分解成多个写操作。这些操作都遵循上述的控制流程，但可能会与其他客户端的并发操作交织在一起并被覆盖。因此，共享文件区域可能会包含来自不同客户端的碎片，尽管副本是相同的，因为所有副本上的操作以相同的顺序成功完成。这样的操作会将文件区域留在一致但未定义的状态，正如第2.7节中所述。

#### 最后一句话什么意思？

最后一句话指的是，这种情况下，共享文件区域的内容可能会包含来自不同客户端的片段，但副本是相同的，因为在所有副本上，单个操作以相同的顺序成功完成。这将使文件区域处于一种一致但未定义的状态。也就是说，这些客户端操作按照一定的顺序被执行，但最终的结果可能是不可预测的。

#### 所以未定义的状态就是说并发导致不同客户端append的记录顺序是我们不可预知的是吗？

是的，因为并发写操作可能会重叠或被覆盖，导致写入相同文件区域的不同记录的顺序是不确定的。这种情况下，文件区域的状态是一致的，因为所有副本中的操作按照相同的顺序完成，但是由于并发的存在，多个客户端写入的记录可能会在同一区域产生交错的现象。因此，这种情况下文件区域的状态是一致但未定义的。

#### 那未定义的状态不就有错误了？为什么不加锁

GFS不加锁是出于性能的考虑。加锁会导致大量的等待时间，而GFS的设计目标是高吞吐量和高可用性。相比于完全避免并发写入，GFS更愿意接受在不同客户端的并发写入中可能存在的未定义状态。

此外，由于GFS是在文件系统级别操作，应用程序一般不会直接访问底层数据，因此未定义状态对应用程序的影响很小。如果应用程序需要保证写入的顺序，它可以在应用程序级别进行序列化，将多个写操作打包成一个原子性的操作。

#### 这样可以保证单个客户端写操作的原子性，但无法保证不同客户端之间写操作的冲突吧

是的，GFS中的写操作并没有使用全局锁，因此无法完全避免不同客户端之间的写操作冲突。在高并发的情况下，这可能会导致一些不确定性的结果。但是，在GFS的设计中，重点是提供高可靠性和高可用性，而不是严格保证数据一致性，因此在这种情况下，GFS选择了一种更加宽松的一致性模型。即使出现数据不一致的情况，GFS客户端代码也会通过重试来处理这些错误。

### 3.2 Data Flow



这段文字介绍了GFS中数据流的设计。GFS将数据流和控制流分离，采用线性的管道式方式将数据推送到chunkservers。为了充分利用每个机器的网络带宽，数据会沿着一条线性的chunkservers链推送，而不是分布在其他拓扑结构（如树形结构）中。为了避免网络瓶颈和高延迟连接，每个机器将数据转发到网络拓扑结构中“最近的”尚未接收数据的机器。GFS的网络拓扑结构相对简单，可以通过IP地址比较准确地估算“距离”。最后，GFS通过在TCP连接上进行数据传输流水线处理来尽量减少延迟。在没有网络拥塞的情况下，将B个字节传输到R个副本的理想耗时为B/T + RL，其中T是网络吞吐量，L是两台机器之间传输字节的延迟。GFS的网络链接通常为100 Mbps（T），L远低于1毫秒。因此，理想情况下可以在大约80毫秒内分发1 MB。



#### 3.3 原子记录追加

GFS提供了一种原子追加操作，称为记录追加。在传统的写入操作中，客户端指定要写入数据的偏移量。并发的写入操作可能导致区域包含来自多个客户端的数据片段，这些操作不可串行化。然而，在记录追加中，客户端仅指定数据。GFS会将数据追加到文件中，至少一次地原子方式（即作为一个连续的字节序列），在GFS选择的一个偏移量上，并将该偏移量返回给客户端。这类似于在Unix中以O_APPEND模式打开文件进行写入，但不会出现多个写入者并发时出现的竞争条件。

记录追加在我们的分布式应用程序中广泛使用，在这些应用程序中，许多位于不同机器上的客户端并发地向同一个文件进行追加。如果使用传统的写入操作，客户端需要额外进行复杂和昂贵的同步，例如通过分布式锁管理器。在我们的工作负载中，这种文件通常用作多生产者/单消费者队列或包含来自许多不同客户端的合并结果。

记录追加是一种变异，遵循3.1节中的控制流，仅在主服务器上需要一些额外的逻辑。客户端将数据推送到文件的最后一个块的所有副本，然后将其请求发送到主服务器。主服务器检查将记录追加到当前块是否会导致该块超过最大大小（64 MB）。如果是，它会将该块填充到最大大小，告诉副本也这样做，并回复客户端，指示下一个块上应重试该操作。（为了保持最坏情况下的分段在可接受的水平上，记录追加被限制为最大块大小的四分之一。）如果记录适合于最大大小，这是常见情况，主服务器将数据追加到其副本，告诉副本在确切的偏移量处写入数据，最后回复客户端成功。

如果记录附加操作在任何副本上失败，则客户端将重试该操作。因此，同一块的副本可能包含不同的数据，可能包括相同记录的完整或部分副本。GFS不能保证所有副本是按字节相同的。它只保证数据至少被作为一个原子单元写入一次。这个属性可以轻松地从这个简单的观察中得出：对于操作报告成功，数据必须已经被写入某个块的所有副本的相同偏移量。此外，此后，所有副本都至少与记录的结尾一样长，因此任何将来的记录都将被分配更高的偏移量或不同的块，即使稍后不同的副本成为主副本。根据我们的一致性保证，成功的记录附加操作写入其数据的区域已被定义（因此一致），而介于区域中的区域是不一致的（因此未定义）。正如我们在第2.7.2节中讨论的那样，我们的应用程序可以处理不一致的区域。

#### 所以其实在内存会有一块缓存，保存所有客户端想向chunkserver数据块写的数据？主副本再调度这些缓存按照一定顺序添加在文件的最后?

是的，客户端会先将数据写入内存缓存，然后发送请求到主副本。主副本在将这些数据添加到文件末尾之前，会先将这些数据追加到最后一块已有数据的数据块的内存缓存中，以确保数据的顺序性。当这些数据被添加到文件末尾后，它们就不再需要被缓存，可以被清空。这样，不同的客户端写入同一文件时，它们不会直接将数据写入磁盘，而是先写入内存缓存，然后由主副本负责将这些数据添加到文件末尾，以保证数据的顺序性，避免数据冲突。==这种方式相当于将锁的作用转移到了主副本上，避免了对整个数据块的锁定，从而提高了系统的并发性能==。

#### 但这样其实是无法保证顺序性?

是的，由于多个客户端的记录追加操作是并发执行的，所以它们在内存缓存中的顺序是不确定的。主副本只会保证将这些缓存中的数据以原子方式追加到文件末尾，但它们的顺序可能与客户端提交它们的顺序不同。因此，如果应用程序需要保证顺序性，那么需要在客户端实现一些额外的逻辑，例如添加序列号或时间戳来标识记录的顺序。











